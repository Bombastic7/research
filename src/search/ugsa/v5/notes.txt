



-- Base Search --

struct Node { state, g, depth, f, u, parent }


openlist = list of Nodes, ordered on min u, then min f, then max g.
closedlist = plain set of Nodes.



ugsa_base_search(s0):
	n0 = { state=s0, g=0, depth=0 }
	
	eval_heuristics(n0)
	openlist.push(n0)
	closedlist.add(n0)
	
	loop:
		n = open.pop()
		if n.state is goal:
			return solution
		
		expand(n)


expand(n):
	for each child of n.state:
	
		if child == n.parent.state:
			continue
	
		edge = edge of n.state to child
		
		childnode = Node {state=child, g = n.g + edge.cost, depth = n.depth + 1, parent=n, f=Null, u=Null}
		
		eval_heuristics(childnode)
		
		
		if child in closedlist and duplicateNode.g > childnode.g:
			remove duplicateNode from closedlist, and openlist if present.
		
		
		if child not in closedlist:
			openlist.push(childnode)
			closedlist.add(childnode)



eval_heuristics(n):
	struct pair { fval, uval }
	
	candidates = vector of pair
	
	For each (cost-to-go, dist-to-go) available for n->state:
		n.f = n->g + cost-to-go
		uval = eval_u(n, cost-to-go, dist-to-go)
		
		candidates.add( {fval=n.f, uval=uval} )
		
	best = x in candidates where x.uval is minimal
	n.f = best.fval
	n.u = best.uval



eval_u(n, h, d):
	return ...


/*
	eval_heuristics(n) determines one or more (cost-to-go, distance-to-go) pairs for n.state. This is a static mapping.
	Sets n.f. Sets n.u by refering to eval_u(n, h, d)
	
	eval_u(n, h, d) returns n's u using n's g, f, depth, and supplied h and d arguments, as well as dynamically changing 
	search behaviour statistics.
	
	Thus there are two components that can be seperated: the method in eval_heuristics() to compute which of pair
	h/d heuristic values to use, and the method used to determin a node's u value.
	
	Min_Cost: 			use cost and depth of the cheapest solution path in abstract space.
	Min_Dist: 			use cost and depth of the shortest.
	Min_Cost_Or_Dist: 	use Min_Cost or Min_Dist, such that the method used gives the node the smallest(or largest?) predicted u value.
	Min_Cost_And_Dist: 	use cost of cheapest path, depth of shortest path.
	
	
	Compute u methods:
	
	Delay: u = wf*f + d * [avg expansions between a node being generated and expanded]
	
	HBF: u = wf*f + bf ** (depth+d) - bf ** depth,  where bf is the heuristic branching factor (on u) of the base space.
	
	
	
	
	
	
	Resorting and Caching of search statistics:
	A resort is a reevaluation of all node's u value, and a resorting of the openlist. It is a way to update the open nodes
	with newer (and more accurate) search statistics. Resorts should occur with decreasing frequency as the search progresses.

	Search statistics may be cached and updated periodically.
	
	The Delay method caches, and updates immediately prior to a resort. i.e. all open nodes generated after resort i and before
	resort i+1 use the same search statistics values to compute u.
	
	The HBF method doesn't cache, each node generated uses the latest search statistics. Resorts are still performed, as HBF starts with
	poor accuracy that improves over time.
	
	
	
	Delay method:
	{
		init():
			nextResort = 16
			lastAvgDelay = 0
			nextAvgDelayAcc = 0

		inform_expansion(n, curExpd):
			nextAvgDelayAcc += curExpd - n.expdAtGen
		
		should_resort(curExpd):
			if curExpd >= nextResort:
				nextResort *= 2
				lastAvgDelay = nextAvgDelayAcc / (curExpd / 2)  //i.e. curExpd/2 = expansions since last resort.
				nextAvgDelayAcc = 0
				return true
			
			return false

		
		compute_u(n, h, d):
			return wf*n.f + d*lastAvgDelay
		
		
		var nextResort, lastAvgDelay, nextAvgDelayAcc
	}
	
	
	HBF method:
	{
		init():
			nextResort = 16
			estHbf = 1
			prevLvlsSum = 0
			curLvlCount = 0
			curLvl = Null;
		
		inform_expansion(n, curExpd):
			assert(n.u >= curLvl)
			
			if(n.u == curLvl):
				curLvlCount++
			else:
				if(curLvl != Null and prevLvlSum != 0):
					estHbf =  (curLvlCount + prevLvlsSum) / prevLvlsSum

				prevLvlsSum 	+= curLvlCount
				curLvlCount 	= 1
				curLvl			= n.u
		
		should_resort(curExpd):
			if curExpd >= nextResort:
				nextResort 		*= 2
				curLvlCount 	= 0
				curLvl			= Null
				return true
			return false
		
		compute_u(n, h, d):
			return wf*n.f + estHbf ** (n.depth + d) - estHbf ** n.depth
		
		
		var nextResort, estHbf, prevLvlsSum, curLvlCount, curLvl
	}
	
	
	
	Static options:
	UCalcMode U_Mode,
	UGSABaseHeuristic H_Mode,
	
	Runtime options:
	"wf": wf value used in u calculation
	"wt": must be 1
	
	U_Mode == HBF:
		"constant bf": number to override bf value in u calculation with. (Optional).
	
	Hardcoded options:
	For both U calc methods:
		Initial_Resort_Expd = 16 // first resort occurs after 16 expansions.
		Resort_Fact = 2 // resort every 16 * 2**N expansions.
		
*/
